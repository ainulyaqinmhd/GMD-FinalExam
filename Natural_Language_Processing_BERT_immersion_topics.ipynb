{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ainulyaqinmhd/GMD-FinalExam-GravityIsYourEnemy/blob/main/Natural_Language_Processing_BERT_immersion_topics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw4KNx2muKl7",
        "outputId": "dd23695e-3bb8-46c8-e578-2825ed5e2e14"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "root_path = 'drive/My Drive/colabnotebooks/newsapi/'\n",
        "import pandas as pd\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbONCKoLrALM"
      },
      "source": [
        "# BERTopic installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3L23ojEq4lb"
      },
      "source": [
        "%%capture\n",
        "!pip install bertopic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iodhELobFtI"
      },
      "source": [
        "%%capture\n",
        "!pip install distributed==2021.9.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1DHuyqJtcC3"
      },
      "source": [
        "# Data\n",
        "\n",
        "Load the data that we want to use for topic modeling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gajm5HxvrXbm"
      },
      "source": [
        "# path to file location on google drive, this is where you should put the data\n",
        "archive = \"/content/drive/My Drive/colabnotebooks/newsapi/newsapi.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ3eRlrmvqp7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "84a1a7a5-f6e2-477b-db2f-cb8057d9d45a"
      },
      "source": [
        "archive_df = pd.json_normalize(\n",
        "    pd.concat(\n",
        "        [pd.read_json(ZipFile(archive).open(i), encoding=\"utf-8\") for i in ZipFile(archive).namelist()],\n",
        "        ignore_index=True\n",
        "    )[\"articles\"]\n",
        "    #column name, if existent\n",
        ")\n",
        "'''\n",
        "alternative: \n",
        "with ZipFile(archive) as z:\n",
        "    with z.open(z.namelist()[0]) as f:\n",
        "        archive_df = pd.read_json(f, encoding=\"utf-8\")\n",
        "\n",
        "archive_df = pd.json_normalize(archive_df[\"articles\"])\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-2681a5d97456>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m archive_df = pd.json_normalize(\n\u001b[1;32m      2\u001b[0m     pd.concat(\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )[\"articles\"]\n",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1238\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/colabnotebooks/newsapi/newsapi.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fucGuTx-5JnD"
      },
      "source": [
        "# convert timestamp to something that is easier to read and work with\n",
        "\n",
        "dates = pd.to_datetime(archive_df[\"publishedAt\"]).dt.date\n",
        "year = dates.apply(lambda x: int(str(x).split(\"-\")[0]))\n",
        "archive_df[\"year\"] = year\n",
        "archive_df.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8VMlofAAnQed"
      },
      "source": [
        "archive_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCMOYdKbyaC7"
      },
      "source": [
        "Next, we remove duplicates or empty entries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aexBi_0UwRBr"
      },
      "source": [
        "# drop rows that have empty 'content' column\n",
        "archive_df = archive_df[archive_df[\"content\"].notna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s7CKi4suyvzc"
      },
      "source": [
        "# drop duplicates\n",
        "# archive_df.drop_duplicates(subset=\"content\", inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m5uopilyNAuB"
      },
      "source": [
        "# archive_df = archive_df[(archive_df[\"year\"] == 2020) & (archive_df[\"source.name\"] == \"The Economist\")]\n",
        "# archive_df = archive_df[archive_df[\"year\"] == 2019]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "k080HBKp4IVe"
      },
      "source": [
        "# reset the index, otherwise everything gets messed up\n",
        "# archive_df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7-TuqLyyiVA"
      },
      "source": [
        "Check the amount of texts that we have:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EFQUSE6DwJJL"
      },
      "source": [
        "len(archive_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pYVa_79s9w7q"
      },
      "source": [
        "archive_df[\"source.name\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhehVysyzEI-"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9BtsFXpzzF61"
      },
      "source": [
        "from bertopic import BERTopic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pM04ql2-zqeP"
      },
      "source": [
        "topic_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True)\n",
        "topics, prob = topic_model.fit_transform(archive_df[\"content\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8MO62eo43AF"
      },
      "source": [
        "# Extracting topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5-RgxJ6d0C2O"
      },
      "source": [
        "# most frequent topics\n",
        "freq = topic_model.get_topic_info(); freq.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4ZRCrX9y4_S1"
      },
      "source": [
        "# most important tokens for a topic\n",
        "topic_model.get_topic(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeFwZzN_5vlM"
      },
      "source": [
        "# Visualization\n",
        "\n",
        "Different visualization options included in BERTopic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggvo1uZZ6IW4"
      },
      "source": [
        "## Visualizing topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dTdsh16C5iNY"
      },
      "source": [
        "topic_model.visualize_topics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH_aUOSC6kgJ"
      },
      "source": [
        "## Visualizing topic probabilities\n",
        "\n",
        "The variable `probabilities` that is returned from `transform()` or `fit_tansform()` can be used to understand how confident BERTopic is that certan topics can be found in a document.\n",
        "\n",
        "Visualize it like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OmZHMgh36Obe"
      },
      "source": [
        "topic_model.visualize_distribution(prob[3], min_probability=0.015)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1Cv3JnQ7iGd"
      },
      "source": [
        "## Visualizing topic hierarchy\n",
        "\n",
        "The created topics can be hierarchically reduced. When knowing how they relate to one another, it might help in selecting `nr_topics` to reduce the number of created topics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "46iG1S2y6-yA"
      },
      "source": [
        "topic_model.visualize_hierarchy(top_n_topics=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0090Qrg38ASy"
      },
      "source": [
        "## Visualize terms\n",
        "\n",
        "Look at selected terms for certain topics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UpiRW0gy75FS"
      },
      "source": [
        "topic_model.visualize_barchart(top_n_topics=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42os9t7E-zkO"
      },
      "source": [
        "## Visualize topic similarity\n",
        "\n",
        "Having generated topic embeddings, through both c-TF-IDF and embeddings, we can create a similarity matrix by simply applying cosine similarities through those topic embeddings. The result will be a matrix indicating how similar certain topics are to each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2avb5jrj8NTU"
      },
      "source": [
        "topic_model.visualize_heatmap(n_clusters=20, width=1000, height=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FmPp9vVHAHs"
      },
      "source": [
        "## Visualizing topics over time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SQF6VLSOHDam"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xDrWpa5AzLp"
      },
      "source": [
        "## Visualize term score decline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eJ8lR9rC_B3u"
      },
      "source": [
        "topic_model.visualize_term_rank()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbPB677aC0i_"
      },
      "source": [
        "# Topic reduction\n",
        "\n",
        "BERTopic offers a way to merge topics. One option is to specify the maximum amount of topics, but if this number is too low, merging occurs for topics that should not be merged.\n",
        "\n",
        "Instead, we will use the paramter \"auto\" to merge topics that have a similarity of at least 0.9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UK5dk6PwuVfF"
      },
      "source": [
        "topic_model_reduced = BERTopic(nr_topics=\"auto\",\n",
        "                               language=\"english\",\n",
        "                               calculate_probabilities=True, \n",
        "                               verbose=True).fit(archive_df[\"content\"])\n",
        "\n",
        "# topic_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True)\n",
        "# topics_reduced, probs_reduced = topic_model.fit_transform(archive_df[\"content\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "loW3YmrM2NWf"
      },
      "source": [
        "topic_model_reduced.get_topic_info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BFggKnTM2Zn_"
      },
      "source": [
        "topic_model_reduced.visualize_topics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UjkSuk6Y29b8"
      },
      "source": [
        "topic_model_reduced.visualize_hierarchy(top_n_topics=98)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5SK2G_jIFDtW"
      },
      "source": [
        "# find all topics related to a given word\n",
        "# TODO: figure out if/how we can comnbine multiple words, this implementation doesn't support it - probably chain multiple requests?\n",
        "topic_model_reduced.find_topics(\"robotics\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eC4LkFPNFoDa"
      },
      "source": [
        "topic_model_reduced.get_topic_info(23)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eqALwPNtNdKh"
      },
      "source": [
        "# docs that are representative for a given topic\n",
        "topic_model_reduced.get_representative_docs(30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VV0hy0_oNuKk"
      },
      "source": [
        "topic_model_reduced.get_topic_info()[\"Name\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vk5XgtgtOH2P"
      },
      "source": [
        "print((topic_model_reduced.get_topic_info(30)[\"Name\"]).to_string().split(\" \")[4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwBZd2BHLU1r"
      },
      "source": [
        "# Word cloud visualization\n",
        "\n",
        "For every topic, get the representative texts and visualize them in a wordcloud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ynTaSgB6kRGU"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "# import tensorflow_text as tf_text\n",
        "import time\n",
        "\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b6b-y8pPqjtz"
      },
      "source": [
        "# Get stopwords, stemmer and lemmatizer\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2XxK535Fq64N"
      },
      "source": [
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RzBcCfzVrAb8"
      },
      "source": [
        "stop_words = stopwords + ['paper', 'study', 'article', 'approach', 'literature', 'data', 'analysis', 'result', \n",
        "                       'results', 'case study', 'case studies', 'chapter', 'findings', 'finding', 'model', 'book', 'conference',\n",
        "                       'say', 'will', 'Mr', 'Ms', 'Mrs', 'year', 'one', 'headline', 'print', 'edition', 'print edition', 'edition headline', 'li', 'ul']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zVe4fTTC67gd"
      },
      "source": [
        "# topic_model_reduced.get_topic_info()[\"Name\"][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "F_xv1U-mMd8U"
      },
      "source": [
        "i = 29\n",
        "\n",
        "most_representative_texts = topic_model_reduced.get_representative_docs(i)\n",
        "most_representative_texts = \" \".join(most_representative_texts).replace(\"\\r\\n\", \" \")\n",
        "\n",
        "tokens = nltk.word_tokenize(most_representative_texts)\n",
        "lemmatized_text = \" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in tokens if w not in string.punctuation])\n",
        "stopworded_text = \" \".join(w for w in nltk.word_tokenize(lemmatized_text) if w not in stop_words)\n",
        "\n",
        "wordcloud = WordCloud(width=900, height=600,\n",
        "                    background_color='white').generate(stopworded_text)\n",
        "\n",
        "# filename = \"/content/drive/MyDrive/colab_data/wordclouds/economist/topic_{}.png\".format(i)\n",
        "filename = \"/content/drive/MyDrive/colab_data/wordclouds/bsh/{}.png\".format((topic_model_reduced.get_topic_info(i)[\"Name\"]).to_string().split(\" \")[4])\n",
        "    \n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.savefig(filename, dpi=400)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K3OJQxZ1qB2-"
      },
      "source": [
        "for i in range(0, 90):\n",
        "    most_representative_texts = topic_model_reduced.get_representative_docs(i)\n",
        "    most_representative_texts = \" \".join(most_representative_texts).replace(\"\\r\\n\", \" \")\n",
        "\n",
        "    tokens = nltk.word_tokenize(most_representative_texts)\n",
        "    lemmatized_text = \" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in tokens if w not in string.punctuation])\n",
        "    stopworded_text = \" \".join(w for w in nltk.word_tokenize(lemmatized_text) if w not in stop_words)\n",
        "\n",
        "    wordcloud = WordCloud(width=900, height=600,\n",
        "                     background_color='white').generate(stopworded_text)\n",
        "\n",
        "    # filename = \"/content/drive/MyDrive/colab_data/wordclouds/economist/topic_{}.png\".format(i)\n",
        "    filename = \"/content/drive/MyDrive/colab_data/wordclouds/bbc/{}.png\".format(topic_model_reduced.get_topic_info()[\"Name\"][i+1])\n",
        "    \n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.savefig(filename, dpi=400)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c91SdSlDeMMs"
      },
      "source": [
        "from keras.models import load_model\n",
        "import joblib\n",
        "# Save model\n",
        "topic_model_reduced.save(\"/content/drive/MyDrive/colab_data/economist/BERT_model\")\t\n",
        "#joblib.dump()\n",
        "\n",
        "\n",
        "#keras.models.save_model(topic_model_reduced, \"/content/drive/MyDrive/colab_data/BERT_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iy-uM1mL-Cfd"
      },
      "source": [
        "# my_model = BERTopic.load(\"my_model\")\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UQgsa7NcLtqr"
      },
      "source": [
        "topic_model_reduced.find_topics(\"kitchen\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rxOLFz1yZ8vQ"
      },
      "source": [
        "topic_model_reduced.find_topics(\"cooking\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SUBpKLXKYhsU"
      },
      "source": [
        "topic_model_reduced.find_topics(\"hidden tech\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JVGnfvj4aHJe"
      },
      "source": [
        "topic_model_reduced.find_topics(\"cyber security\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PVPtF_8mYge7"
      },
      "source": [
        "topic_model_reduced.find_topics(\"self sufficiency\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y3ADAcyxYf7A"
      },
      "source": [
        "topic_model_reduced.find_topics(\"circular economy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YFoZ7-ClYg4F"
      },
      "source": [
        "topic_model_reduced.find_topics(\"cloud computing\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ckHfS6J7YhVV"
      },
      "source": [
        "topic_model_reduced.find_topics(\"recommendation systems\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cmYO7a29Lxnm"
      },
      "source": [
        "topic_model_reduced.get_topic_info(13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OxXH0KNuMPaS"
      },
      "source": [
        "topic_model_reduced.get_topic_info(6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vHmFf00gMRVo"
      },
      "source": [
        "topic_model_reduced.get_topic_info(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jxPKPAOaMS9j"
      },
      "source": [
        "topic_model_reduced.get_topic_info(18)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sxuOnBMMMUUg"
      },
      "source": [
        "topic_model_reduced.get_topic_info(88)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IiCOI4wHMVZf"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}